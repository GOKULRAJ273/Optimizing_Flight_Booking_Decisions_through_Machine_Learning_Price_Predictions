# -*- coding: utf-8 -*-
"""Fligth booking.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i6o6gk9td2Eli5g5O1WnGr3L_A3Sq1HA
"""

import numpy as np
import pandas as pd 
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import f1_score
from sklearn.metrics import classification_report, confusion_matrix
import warnings
import pickle
from scipy import stats
warnings.filterwarnings('ignore')

# Load the data directly from the Excel file
data = pd.read_csv('/content/Data_Train.csv')

# Print the first few rows of the data
print(data.head())

# Print the unique values in each categorical column
for i in data.select_dtypes(include='object'):
    print(i, data[i].unique())

data = data.rename(columns={'Date_of_Journey': 'Data_of_Journey'})
data.Data_of_Journey = data.Data_of_Journey.str.split('/')

data.columns

data['Data_of_Journey']

data['Date']=data['Data_of_Journey'].str[0]
data['Month']=data['Data_of_Journey'].str[1]
data['Year']=data['Data_of_Journey'].str[2]

data.Total_Stops.unique()

data.Route=data.Route.str.split('->')

data['City1']=data.Route.str[0]
data['City2']=data.Route.str[1]
data['City3']=data.Route.str[2]
data['City4']=data.Route.str[3]
data['City5']=data.Route.str[4]
data['City6']=data.Route.str[5]

data.Dep_Time=data.Dep_Time.str.split(':')

data['Dep_Time_Hour']=data.Dep_Time.str[0]
data['Dep_Time_Mins']=data.Dep_Time.str[1]

data.Arrival_Time=data.Arrival_Time.str.split('')

data['Arrival_date']=data.Arrival_Time.str[1]
data['Time_of_Arrival']=data.Arrival_Time.str[0]

data['Time_of_Arrival']=data.Time_of_Arrival.str.split(':')

data['Arrival_Time_Hour']=data.Time_of_Arrival.str[0]
data['Arrival_Time_Mins']=data.Time_of_Arrival.str[1]

data.Duration=data.Duration.str.split(' ')

data['Travel_Hours']=data.Duration.str[0]
data['Travel_Hours']=data['Travel_Hours'].str.split('h')
data['Travel_Hours']=data['Travel_Hours'].str[0]
data.Travel_Hours=data.Travel_Hours
data["Travel_Mins"]=data.Duration.str[1]

data.Travel_Mins=data.Travel_Mins.str.split('a') 
data.Travel_Mins=data.Travel_Mins.str[0]

data.Total_Stops.replace('non_stop',0,inplace=True)
data.Total_Stops=data.Total_Stops.str.split(' ')
data.Total_Stops=data.Total_Stops.str[0]

data.Additional_Info.unique()

data.Additional_Info.replace('No Info','No info',inplace=True)

data.isnull().sum()

data.drop(['City4','City5','City6'],axis=1,inplace=True)

# Check if the columns exist in the dataframe
print(data.columns)

# Remove any columns that are not present in the dataframe
columns_to_drop = ['Date_of_Journey', 'Route', 'Dep_Time', 'Arrival_Time', 'Duration']
columns_to_drop = [col for col in columns_to_drop if col in data.columns]

# Drop the columns from the dataframe
data.drop(columns_to_drop, axis=1, inplace=True)

# Check the updated dataframe
print(data.head())

data.isnull().sum()

data['City3'].fillna('None',inplace=True)

data['Arrival_date'].fillna('None',inplace=True)

data['Travel_Mins'].fillna('None',inplace=True)

data.info()

data['Travel_Mins'] = data['Travel_Mins'].str.rstrip('m')  # remove 'm' character from the end of each string
data['Travel_Mins'] = data['Travel_Mins'].replace('None', '-1')  # replace 'None' values with -1
data['Travel_Mins'] = data['Travel_Mins'].astype('int64')   # convert to int64 datatype

#data['Total_Stops'] = data['Total_Stops'].astype('int64')
data['Date'] = data['Date'].astype('int64')
data['Month'] = data['Month'].astype('int64')
data['Year'] = data['Year'].astype('int64')
data['Dep_Time_Hour'] = data['Dep_Time_Hour'].astype('int64')
data['Dep_Time_Mins'] = data['Dep_Time_Mins'].astype('int64')
data['Arrival_date'] = data['Arrival_date'].astype('int64')
data['Arrival_Time_Mins'] = data['Arrival_Time_Mins'].fillna(-1).astype('int64')
#data['Travel_Hours'] = data['Travel_Hours'].astype('int64')
data['Travel_Mins'] = data['Travel_Mins'].astype('int64')

data[data['Travel_Hours']=='5']

data.drop(index=6474,inplace=True,axis=0)

data.Travel_Hours=data.Travel_Hours.astype('int64')

"""Label Encoding"""

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()

data.Airline=le.fit_transform(data.Airline)
data.Source=le.fit_transform(data.Source) 
data.Destination=le.fit_transform(data.Destination)
data.Total_Stops=le.fit_transform(data.Total_Stops) 
data.Cityl=le.fit_transform(data.City1) 
data.City2=le.fit_transform(data.City2)
data.City3=le.fit_transform(data.City3) 
data.Additional_Info=le.fit_transform(data. Additional_Info)
data.head()

data = data[['Airline','Source','Destination','Date','Month','Year','Dep_Time_Hour','Dep_Time_Mins','Dep_Time_Mins','Arrival_date','Arrival_Time_Hour','Arrival_Time_Mins','Price']]

data.head()

data.describe()

import seaborn as sns
import matplotlib.pyplot as plt

# Define categorical variables
categorical = ['Airline', 'Source', 'Destination', 'Additional_Info', 'City1']

# Create a plot for each categorical variable
c = 1
plt.figure(figsize=(10,20))
for i in data.columns: 
    if i in categorical:
        plt.subplot(6,3,c)
        sns.countplot(x=data[i])
        plt.xticks(rotation=90)
        plt.tight_layout(pad=3.0)
        c=c+1  
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(15,8))
sns.distplot(data['Price'])

sns.heatmap(data.corr(),annot=True)

import seaborn as sns 
sns.boxplot(data['Price'])

y = data['Price']
x = data.drop(columns=['Price','Arrival_Time_Hour'],axis=1)

from sklearn.preprocessing import StandardScaler
ss = StandardScaler()

data.info()

x_scaled = ss.fit_transform(x)

x_scaled = pd.DataFrame(x_scaled)
x_scaled.head()

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2, random_state=42)

x_train.head()

from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor
rfr=RandomForestRegressor()
gb=GradientBoostingRegressor()
ad=AdaBoostRegressor()

from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

for i in [rfr, gb, ad]:
    i.fit(x_train, y_train)
    y_pred = i.predict(x_test)
    test_score = r2_score(y_test, y_pred)
    train_score = r2_score(y_train, i.predict(x_train))
    
    if abs(train_score - test_score) <= 0.2:
        print(i)
        print("R2 score is", test_score)
        print("R2 for train data", train_score)
        print("Mean Absolute Error is", mean_absolute_error(y_pred, y_test))
        print("Mean Squared Error is", mean_squared_error(y_pred, y_test))
        print("Root Mean Absolute Error is", mean_squared_error(y_pred, y_test, squared=False))

from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor

from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error

knn=KNeighborsRegressor()
svr=SVR()
dt=DecisionTreeRegressor()
for i in [knn,svr,dt]: 
    i.fit(x_train,y_train)
    y_pred=i.predict(x_test) 
    test_score=r2_score (y_test,y_pred)
    train_score=r2_score(y_train,i.predict(x_train))
    if abs(train_score-test_score)<=0.1: 
        print(i)
        print('R2 Score is',r2_score(y_test,y_pred))
        print('R2 Score for train data',r2_score(y_train,i.predict(x_train))) 
        print('Mean Absolute Error is', mean_absolute_error(y_test,y_pred))
        print('Mean Squared Error is',mean_squared_error(y_test,y_pred)) 
        print('Root Mean Squared Error is', (mean_squared_error(y_test,y_pred,squared=False)))

from sklearn.model_selection import cross_val_score
for i in range(2,5):
    cv=cross_val_score(rfr,x,y,cv=i)
    print(rfr,cv.mean())

from sklearn.model_selection import RandomizedSearchCV

param_grid={'n_estimators': [10,30,50,70,100],"max_depth": [None,1,2,3],
'max_features':['auto', 'sqrt']}
rfr=RandomForestRegressor()
rf_res=RandomizedSearchCV(estimator=rfr, param_distributions=param_grid,cv=3,verbose=2,n_jobs=-1)

rf_res.fit(x_train,y_train)

gb=GradientBoostingRegressor()
gb_res=RandomizedSearchCV(estimator=gb, param_distributions=param_grid, cv=3, verbose=2,n_jobs=-1)

gb_res.fit(x_train,y_train)

rfr=RandomForestRegressor(n_estimators=10,max_features="sqrt",max_depth=None)
rfr.fit(x_train,y_train)
y_train_pred=rfr.predict(x_train)
y_test_pred=rfr.predict(x_test)
print("train accuracy",r2_score(y_train_pred,y_train)) 
print("test accuracy",r2_score(y_test_pred,y_test))

knn=KNeighborsRegressor (n_neighbors=2, algorithm="auto", metric_params=None,n_jobs=-1)
knn.fit(x_train,y_train)
y_train_pred=knn.predict(x_train) 
y_test_pred=knn.predict(x_test)
print("train accuracy", r2_score (y_train_pred,y_train))
print("test accuracy",r2_score(y_test_pred,y_test))

Price=y_train_pred

price_list=pd.DataFrame({'Price':Price})

price_list

import pickle
pickle.dump(rfr,open('model1.pkl','wb'))